---
title: "R for Data Science Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

# Data Visualization with ggplot2
1.1 INTRODUCTION Plot fuel efficiency on highway against the car's engine size
```{r}
library(tidyverse)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
```

1.2 AESTHETIC MAPPING Add aesthetic property to car's class

```{r}
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, color = class))
```

Set aesthetic properties of the geom manually - color outside aesthetics, don't convey info about variables

```{r}
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy), color = "blue"
)
```

1.3 FACETS Split your plot into facets, subplots that each display one subset of the data.

```{r}
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(drv ~ cyl)

ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(. ~ cyl)
```

1.4 GEOMETRIC OBJECTS Change geom in ggplot2 syntax and map aesthetic to a discrete variable to draw multiple objects.

```{r}
ggplot(data = mpg) +
geom_smooth(mapping = aes(x = displ, y = hwy)) 

ggplot(data = mpg) +
geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),
show.legend = FALSE)
```
Display multiple geoms in the same plot, passing the mapping to ggplot().
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point() +
geom_smooth()
```
Local data argument in a geom function overwrites the global mappings for that layer only.

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = class)) +
geom_smooth(
data = filter(mpg, class == "subcompact"),
se = FALSE
)

```
1.5 STATISTICAL TRANSFORMATIONS interchangeable bar chart plot and stat count for diamonds.
*This works because every geom has a default stat, and every stat has a default geom.*

```{r}
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))
ggplot(data = diamonds) +
stat_count(mapping = aes(x = cut))

```
1.6 POSITION ADJUSTMENTS add color aesthetics to bar charts - map fill aesthetic to another variable, bars are automatically stacked
*question - what does "position" and "identity" truly mean? and why would overlap occur? pp. 28*
position = "identity" will place each object exactly where it falls in the context of the graph. This is not very useful for bars, because it overlaps them. To see that overlapping we either need to make the bars slightly transparent by setting alpha to a small value, or completely transparent by setting fill = NA:
```{r}
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity))
 
ggplot(
data = diamonds,
mapping = aes(x = cut, fill = clarity)
) +
geom_bar(alpha = 1/5, position = "identity")
ggplot(
data = diamonds,
mapping = aes(x = cut, color = clarity)
) +
geom_bar(fill = NA, position = "identity")

ggplot(
data = diamonds,
mapping = aes(x = cut, fill = clarity)
) +
geom_bar(position = "identity")
```
Position = “fill" is used for comparing proportion values; Position = "dodge" is used for comparing individual values
```{r}
ggplot(data = diamonds) +
geom_bar(
mapping = aes(x = cut, fill = clarity),
position = "fill"
)

ggplot(data = diamonds) +
geom_bar(
mapping = aes(x = cut, fill = clarity),
position = "dodge"
)
```
Add random noise to the plot to reveal spreads of data points using Position = "jitter"

```{r}
ggplot(data = mpg) +
geom_point(
mapping = aes(x = displ, y = hwy),
position = "jitter"
)
```
1.7 COORDINATE SYSTEM
The default coordinate system is the Cartesian coordinate system where the x and y position act independently to find the location of each point.

coord_flip () switches x and y position to avoid overlapping on x-axes.

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() +
coord_flip()
```
coord_polar() uses polar coordinates. Polar coordinates reveal an interesting connection between a bar chart and a Coxcomb
chart

```{r}
bar <- ggplot(data = diamonds) +
geom_bar(
mapping = aes(x = cut, fill = clarity),

) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL)
bar + coord_flip()
bar + coord_polar()
```
# Data Transformation with dplyr
```{r}
install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
?flights
flights
```

3.1 Variable Type:
• int stands for integers.
• dbl stands for doubles, or real numbers.
• chr stands for character vectors, or strings.
• dttm stands for date-times (a date + a time).
• lgl stands for logical, vectors that contain only TRUE or FALSE.
• fctr stands for factors, which R uses to represent categorical
variables with fixed possible values.
• date stands for dates.

3.2 dplyr Basics:
Language of Data Manipulation:
• Pick observations by their values (filter()).
• Reorder the rows (arrange()).
• Pick variables by their names (select()).
• Create new variables with functions of existing variables
(mutate()).
• Collapse many values down to a single summary (summa
rize()).
• group_by(), which changes the scope of each function from operating on the entire dataset to operating on it group-by-group.

3.3 Filter Rows with filter()
dplyr executes the filtering operation and returns a new data frame.

```{r}
filter(flights, month == 1, day == 1)
```

if you want to save the result, you’ll need to use the assignment operator, <-:

```{r}
jan1 <- filter(flights, month == 1, day == 1)
```

If you want to do both, you can wrap the assignment in parentheses:

```{r}
(dec25 <- filter(flights, month == 12, day == 25))
```

Comparisons and Boolean operators:
1. R provides the standard suite: >, >=, <, <=, != (not equal), and == (equal).
2. & is “and,” | is “or,” and ! is “not.”
3. De Morgan’s law: !(x & y) is the same as !x | !y, and !(x | y) is the same as !x & !y.
Example:

```{r}
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)
```
4. Problem with month = 11|12 -> becomes month = 1. A useful shorthand for this problem is x %in% y.
```{r}
(nov_dec <- filter(flights, month %in% c(11, 12)))
```
Missing Values:
NA represents an unknown value so missing values are “contagious”; almost any operation involving an unknown value will also be unknown
Need to manually include NA values in filtering:
```{r}
(df <- tibble(x = c(1, NA, 3)))
```

3.4 Arrange Rows with arrange()
1. Missing values are always sorted at the end:
2. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns
3. Use desc() to reorder by a column in descending order

How to sort all missing values to the start? use is.na()
```{r}
df <- tibble(x = c(5, 2, NA))
arrange(df, desc(is.na(x)))

```
3.5 Select Columns with select()

```{r}
# Select all columns between year and day (inclusive)
select(flights, year:day)
# Select all columns except those from year to day (inclusive)
select(flights, -(year:day))
```

There are a number of helper functions you can use within select():
• starts_with("abc") matches names that begin with “abc”.
• ends_with("xyz") matches names that end with “xyz”.
• contains("ijk") matches names that contain “ijk”.
• matches("(.)\\1") selects variables that match a regular expression. This one matches any variables that contain repeated characters. You’ll learn more about regular expressions
in Chapter 11.
*what is (.)\\1?*
• num_range("x", 1:3) matches x1, x2, and x3.

use rename(), which is a variant of select() that keeps all the variables that aren’t explicitly mentioned

```{r}
rename(flights, tail_num = tailnum)
```
Another option is to use select() in conjunction with the every thing() helper. This is useful if you have a handful of variables you’d like to move to the start of the data frame

```{r}
select(flights, time_hour, air_time, everything())
```
3.6 Add New Variables With mutate(); mutate adds new variables to the end of the dataset; if only wants to keep new variables created, use transmute
```{r}
flights_sml <- select(flights,
year:day,
ends_with("delay"),
distance,
air_time
)
mutate(flights_sml,
gain = arr_delay - dep_delay,
speed = distance / air_time * 60)

transmute(flights,
gain = arr_delay - dep_delay,
hours = air_time / 60,
gain_per_hour = gain / hours
)
```

#Useful Creation Functions
1. Arithmetic operations - +,-,*,/,^
2. Modeular arithmetic (%/% integer division; %% remainder)
3. Logs log(), log2(), log10(). - I recommend using log2() because it’s easy to interpret: a difference of 1 on the log scale corresponds to doubling on the original scale and a difference of –1 corresponds to halving.
4. *offsets lag() and lead()* not sure what this means? 
5. Cumulative and running means - R provides functions for running sums, products, mins, and maxes: cumsum(), cumprod(), cummin(), cummax(); and dplyr provides cummean() for cumulative means.
6. Logical comparisons
7. Ranking - min_rank(), row_number(), dense_rank(), percent_rank(), cume_dist(),
row_number(): equivalent to rank(ties.method = "first")
min_rank(): equivalent to rank(ties.method = "min")
dense_rank(): like min_rank(), but with no gaps between ranks
percent_rank(): a number between 0 and 1 computed by rescaling min_rank to [0, 1]
cume_dist(): a cumulative distribution function. Proportion of all values less than or equal to the current rank.
ntile(): a rough rank, which breaks the input vector into n buckets. The size of the buckets may differ by up to one, larger buckets have lower rank.



```{r}
library(dplyr)
library(nycflights13)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled
not_cancelled %>%
group_by(year, month, day) %>%
summarize(mean = mean(dep_delay))
```

3.7 Grouped Summaries with summarize()
This verb is not particularly useful unless paired with group_by()

```{r}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

3.8 Combining Multiple Operations with the Pipe
Example: explore relationship between distance and arrival delay
There are three steps to prepare this data:
1. Group flights by destination.
2. Summarize to compute distance, average delay, and number of flights.
3. Filter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport.
```{r}
by_dest <- group_by(flights, dest)
delay <- summarize(by_dest,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")
# It looks like delays increase with distance up to ~750 miles
# and then decrease. Maybe as flights get longer there's more
# ability to make up delays in the air?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
geom_point(aes(size = count), alpha = 1/3) +
geom_smooth(se = FALSE)
#> `geom_smooth()` using method = 'loess'
```

logic of pipe: x %>% f(y) turns into f(x, y), and x %>% f(y) %>% g(z) turns into g(f(x, y), z)
```{r}
delays <- flights %>%
group_by(dest) %>%
summarize(
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
) %>%
filter(count > 20, dest != "HNL")
```
All aggregation functions have an na.rm argument, whcih removes the missing values prior to computation - add na.rm = TRUE to the argument when summarizing dataframe
```{r}
flights %>%
group_by(year, month, day) %>%
summarize(mean = mean(dep_delay))
flights %>%
group_by(year, month, day) %>%
summarize(mean = mean(dep_delay, na.rm = TRUE))

```

```{r}
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarize(
delay = mean(arr_delay, na.rm = TRUE),
n = n()
)
ggplot(data = delays, mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
```
Not surprisingly, there is much greater variation in the average delay when there are few flights. The shape of this plot is very characteristic: whenever you plot a mean (or other summary) versus group size, you’ll see that the variation decreases as the sample size increases.

```{r}
delays %>%
filter(n > 25) %>%
ggplot(mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
```
#Useful Summary Functions
1. Measures of location - median()
2. Measures of spread sd(x), IQR(x), mad(x) - median absolute deviation()
3. Measures of rank min(x), quantile(x, 0.25), max(x)  
4. Measures of position first(x), nth(x, 2), last(x) *why are measures of position complimentary to filtering on ranks?*
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  mutate(r = min_rank(desc(dep_time))) %>%
  filter(r %in% range(r))%>% #didn't understand this line
  select(year, month, day, r, everything())
```

5. Counts - 
To count the number of non-missing values, use sum(!is.na(x)). 
To count the number of distinct (unique) values, use n_distinct(x):
```{r}
not_cancelled %>%
group_by(dest) %>%
summarize(carriers = n_distinct(carrier)) %>%
arrange(desc(carriers))
```

6. Counts and proportions of logical values sum(x > 10), mean(y == 0); sum shows the total number of TRUEs in x, whereas mean gives the proportion of TRUEs
```{r}
# How many flights left before 5am? (these usually
# indicate delayed flights from the previous day)
not_cancelled %>%
group_by(year, month, day) %>%
summarize(n_early = sum(dep_time < 500))
```

3.9 Grouping by Multiple Variables 
1. each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset
2. Be careful when progressively rolling up summaries: it’s OK for sums and counts, but you need to think about weighting means and variances, and it’s not possible to do it exactly for rank-based statistics like the median. *how to weight the means and variance when grouping by multiple variables?*

3.10 Grouped Mutates and Filters
Example 1: Find the worst member in the group:
```{r}
flights_sml %>%
group_by(year, month, day) %>%
filter(rank(desc(arr_delay)) < 10)
```
Example 2: Find all groups bigger than a threshold and standardize to compute per group metrics
```{r}
popular_dests <- flights %>%
group_by(dest) %>%
filter(n() > 365)
popular_dests
popular_dests %>%
filter(arr_delay > 0) %>%
mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
select(year:day, dest, arr_delay, prop_delay)
```

#Exploratory Data Analysis
##5.1 Introduction - the mindset of EDA
1. generate questions
2. visualize, transform and model
3. generate new questions/refine

##5.2 Variation 
Every variable has its own pattern of variation, which can reveal interesting information. The best way to understand that pattern is to visualize the distribution of variables’ values.

Visualize Distribution:
- Bar Chart for categorical variables
- Histogram for continuous variables - *binwidth is used to set the width of the intervals*
```{r}
ggplot(data = diamonds) +
geom_histogram(mapping = aes(x = carat), binwidth = 0.5)

smaller <- diamonds %>%
  filter(carat < 3)
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.1)
```
Use freqpoly to overlay multiple histograms
```{r}
ggplot(data = smaller, mapping = aes(x = carat, color = cut)) +
geom_freqpoly(binwidth = 0.1)
```

Typical Values - most common values, show clusters
Unusual Values - outliers or data entry errors, use coor_cartesian() to zoom in to small values

```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```
Deal with unusual values:
1. remove the entire rows (not recommended)
2. set the unusual values to missing
itself() function has three arguments, the first specifies a logical vector, second is the value it takes if the test is TRUE, third is the value it takes if it is FALSE.
```{r}
diamonds2 <- diamonds %>%
mutate(y = ifelse(y < 3 | y > 20, NA, y))
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) +
  geom_point(na.rm = TRUE)
```
Understand what makes observations with missing values different from observations with recorded values
```{r}
nycflights13::flights %>%
mutate(
  cancelled = is.na(dep_time),
  sched_hour = sched_dep_time %/% 100,
  sched_min = sched_dep_time %% 100,
  sched_dep_time = sched_hour + sched_min / 60
) %>%
ggplot(mapping = aes(sched_dep_time)) +
  geom_freqpoly(
    mapping = aes(color = cancelled),
    binwidth = 1/4
)+
  coord_cartesian(ylim=c(0,500))
```

##5.3 Covariation
Covariation is the tendency for the values of two or more variables to vary together in a related way.

5.3.1 A categorical and continuous variable 
1. display density using freqpoly
```{r}
ggplot(
data = diamonds,
mapping = aes(x = price, y = ..density..)
) +
geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```
2. use boxplot and reorder() function to make the trend easier to see (only applicable to categorical variables with no explicit order?reorder)
```{r}
ggplot(data = mpg) +
geom_boxplot(
mapping = aes(
x = reorder(class, hwy, FUN = median),
y = hwy
)
)
```
5.3.2 Two Categorical Variables
need to count the number of observations for each combination.
1. Use geom_count to map out the 
```{r}
ggplot(data = diamonds) +
geom_count(mapping = aes(x = cut, y = color))
```
2. Use dplyr package to count and use geom_tile to map out

```{r}
diamonds %>%
count(color, cut) %>%
ggplot(mapping = aes(x = color, y = cut)) +
geom_tile(mapping = aes(fill = n))
```

5.3.3  Two Continuous Variables
use geom_point to plot scatterplot. 
```{r}
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price))
```
1. use alpha to add transparency to avoid overplot due to large sample size
```{r}
ggplot(data = diamonds) +
geom_point(
mapping = aes(x = carat, y = price),
alpha = 1 / 100
)
```
2. use geom_bin2d and geom_hex to display 2D bins

```{r}
ggplot(data = smaller) +
geom_bin2d(mapping = aes(x = carat, y = price))
# install.packages("hexbin")
ggplot(data = smaller) +
geom_hex(mapping = aes(x = carat, y = price))
```
3. bin one variable so it acts like a categorical variable; use boxplots to display relationship between the categorical variable and another continuous variable
```{r}
# cut_width restricts the width of each bin to be the same, however each bin could contain drastically different values
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
# cut_number restricts the number each bin has to display the number distribution
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
```
5.4 Patterns and Models
If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it. 
If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second

Model: remove strong relationships to discern the subtlties that remain. 

```{r}
library(modelr)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>%
add_residuals(mod) %>%
mutate(resid = exp(resid))

ggplot(data = diamonds2) +
geom_point(mapping = aes(x = carat, y = resid))

ggplot(diamonds2) +
geom_boxplot(aes(cut, resid))
```

# Data Wrangling: tidy data
8.2 readr - turning flat files into data frames
Use skip, comment #, col_names to create column names

```{r}
read_csv("The first line of metadata
The second line of metadata
x,y,z
1,2,3", skip = 2)

read_csv("# A comment I want to skip
x,y,z
1,2,3", comment = "#")

read_csv("1,2,3\n4,5,6", col_names = FALSE)

read_csv("1,2,3\n4,5,6", col_names = c("x", "y", "z"))

read_csv("a,b,c\n1,2,.", na = ".")
```

8.3 Parsing a vector
Use parse_*() function to take a character vector an dreturn a specialized vector like a logical, integer or date.

```{r}
str(parse_logical(c("TRUE", "FALSE", "NA")))
str(parse_integer(c("1", "2", "3")))
str(parse_date(c("2010-01-01", "1979-10-14")))
```

parsing failures:

```{r}
x <- parse_integer(c("123", "345", "abc", "123.45"))
x
problems(x)
```

8.3.1 Numbers
3 major problems:
• People write numbers differently in different parts of the world.
For example, some countries use . in between the integer and
fractional parts of a real number, while others use ,.

```{r}
parse_double("1,23", locale = locale(decimal_mark = ","))
```

• Numbers are often surrounded by other characters that provide
some context, like “$1000” or “10%”.

```{r}
parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45")
```

• Numbers often contain “grouping” characters to make them
easier to read, like “1,000,000”, and these grouping characters
vary around the world.

```{r}
parse_number(
"123.456.789",
locale = locale(grouping_mark = ".")
)
parse_number(
"123'456'789",
locale = locale(grouping_mark = "'")
)
```

8.3.2 Strings
Different character encoding standards are adopted in different locations. 
specify the encoding in parse_char acter():
```{r}
charToRaw("Hadley")

x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"

parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
```

8.3.4 Dates, Date-Times, and Times

```{r}
parse_datetime("2010-10-01T2010")
parse_datetime("20101010")
library(hms)
parse_time("01:10 am")
parse_time("20:10:01")
```

8.4 Parsing Files
guess_parser() = returns readr's guess of character vector type; parse_guess() = uses that guess to parse the column

```{r}
guess_parser("2010-10-01")
str(parse_guess("2010-10-10"))
```

Problems
• The first thousand rows might be a special case, and readr
guesses a type that is not sufficiently general. For example, you
might have a column of doubles that only contains integers in
the first 1000 rows.
• The column might contain a lot of missing values. If the first
1000 rows contain only NAs, readr will guess that it’s a character
vector, whereas you probably want to parse it as something
more specific.
```{r}
challenge <- read_csv(readr_example("challenge.csv"))
problems(challenge)

```

Solve the problem by changing column specification.

```{r}
challenge <- read_csv(
readr_example("challenge.csv"),
col_types = cols(
x = col_double(),
y = col_date()
)
)
tail(challenge)
```
```{r}
challenge2 <- read_csv(
readr_example("challenge.csv"),
guess_max = 1001
)
challenge2
```

```{r}
challenge2 <- read_csv(readr_example("challenge.csv"),
col_types = cols(.default = col_character())
)

df <- tribble(
~x, ~y,
"1", "1.21",
"2", "2.32",
"3", "4.56"
)
df
type_convert(df)
```
Write files

```{r}
write_csv(challenge, "challenge-2.csv")
read_csv("challenge-2.csv")
```

```{r}
library(feather)
write_feather(challenge, "challenge.feather")
read_feather("challenge.feather")
```
# Data Tidying With tidyr
**There are three interrelated rules which make a dataset tidy:**
1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

Problems with real analysis 
• One variable might be spread across multiple columns.
• One observation might be scattered across multiple rows.

9.1 Gathering
9.1.1 A common problem is a dataset where some of the column names are not names of variables, but values of a variable.
• The set of columns that represent values, not variables. In this
example, those are the columns 1999 and 2000.
• The name of the variable whose values form the column names.
I call that the key, and here it is year.
• The name of the variable whose values are spread over the cells.
I call that value, and here it’s the number of cases.

```{r}
library(tidyr)
table4a
table4a %>%
gather(`1999`, `2000`, key = "year", value = "cases")
table4b %>%
gather(`1999`, `2000`, key = "year", value = "population")
```

9.2 Spreading
You use it when an observation is scattered across multiple rows.
• The column that contains variable names, the key column. Here, it’s type.
• The column that contains values forms multiple variables, the value column. Here, it’s count.

```{r}
table2
spread(table2, key = type, value = count)
```

9.3 Separating and Pull
table3 has a different problem: we have one column (rate) that contains two variables (cases and population).
use convert to change data type from default character to others 

```{r}
table3
table3 %>%
separate(rate, into = c("cases", "population"), 
         convert=TRUE)
```

Use unite() to combine multiple columns into a single column. Use sep to delete the default _ that is created when combining. 
```{r}
table5 %>%
  unite(new, century, year)
table5 %>%
  unite(new, century, year, sep = "")
```

9.4 Missing Values
a value can be missing in one of two possible ways:
• Explicitly, i.e., flagged with NA.
• Implicitly, i.e., simply not present in the data.

```{r}
stocks <- tibble(
year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
qtr = c( 1, 2, 3, 4, 2, 3, 4),
return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)
)
stocks
```

• The return for the fourth quarter of 2015 is explicitly missing,
because the cell where its value should be instead contains NA.
• The return for the first quarter of 2016 is implicitly missing,
because it simply does not appear in the dataset.

Set implicit missing values to explicit.
```{r}
stocks %>%
spread(year, return)
stocks %>%
complete(year, qtr)
```
Set implicit missing values to explicit. 

```{r}
stocks %>%
spread(year, return) %>%
gather(year, return, `2015`:`2016`, na.rm = TRUE)
```
You can fill in these missing values with fill(). 
It takes a set of columns where you want missing values to be replaced by the most recent nonmissing value (sometimes called last observation carried forward):

```{r}
treatment <- tribble(
~ person, ~ treatment, ~response,
"Derrick Whitmore", 1, 7,
NA, 2, 10,
NA, 3, 9,
"Katherine Burke", 1, 4
)
treatment %>%
fill(person)
```


# Relational Data with dplyr

```{r}
library(tidyverse)
library(nycflights13)
```

10.1 Keys
The variables used to connect each pair of tables are called keys. A
key is a variable (or set of variables) that uniquely identifies an
observation.

• A primary key uniquely identifies an observation in its own
table. For example, planes$tailnum is a primary key because it
uniquely identifies each plane in the planes table.
• A foreign key uniquely identifies an observation in another
table. For example, flights$tailnum is a foreign key because it
appears in the flights table where it matches each flight to a
unique plane.

Identify primary key and verify it using count() and filter() functions.

```{r}

planes %>%
count(tailnum) %>%
filter(n > 1)

flights %>%
count(year, month, day, flight) %>%
filter(n > 1)
```

If a table lacks a primary key, it’s sometimes useful to add one with mutate() and row_number().
That makes it easier to match observations if you’ve done some filtering and want to check back in with the original data. This is called a surrogate key.

10.2 Mutating Joins

Combine a pair of tables to the right. 

```{r}
flights2 <- flights %>%
select(year:day, hour, origin, dest, tailnum, carrier)
flights2

flights2 %>%
select(-origin, -dest) %>%
left_join(airlines, by = "carrier")
```

```{r}
x <- tribble(
~key, ~val_x,
1, "x1",
2, "x2",
3, "x3"
)

y <- tribble(
~key, ~val_y,
1, "y1",
2, "y2",
4, "y3"
)
```

In an actual join, matches will be indicated with dots. The number of dots = the number of matches = the number of rows in the output.

10.2.1 Inner Join
* The simplest type of join is the inner join. An inner join matches pairs of observations whenever their keys are equal:
* The output of an inner join is a new data frame that contains the key, the x values, and the y values. We use by to tell dplyr which variable is the key

```{r}
x %>%
inner_join(y, by = "key")
```
10.2.2 Outer Joins
An outer join keeps observations that appear in at least one of the tables.
• A left join keeps all observations in x.
• A right join keeps all observations in y.
• A full join keeps all observations in x and y.

The left join should be your default join: use it unless you have a strong reason to
prefer one of the others.

10.2.3 Duplicate Keys
1. One table has duplicate keys. This is useful when you want to
add in additional information as there is typically a one-tomany
relationship:
```{r}
x <- tribble(
~key, ~val_x,
1, "x1",
2, "x2",
2, "x3",
1, "x4"
)
y <- tribble(
~key, ~val_y,
1, "y1",
2, "y2"
)
left_join(x, y, by = "key")
```

2. Both tables have duplicate keys. This is usually an error because
in neither table do the keys uniquely identify an observation.
When you join duplicated keys, you get all possible combinations,
the Cartesian product:
```{r}
x <- tribble(
~key, ~val_x,
1, "x1",
2, "x2",
2, "x3",
3, "x4"
)
y <- tribble(
~key, ~val_y,
1, "y1",
2, "y2",
2, "y3",
3, "y4"
)
left_join(x, y, by = "key")
```
10.2.4 Defining the Key Columns
1. The default, by = NULL, uses all variables that appear in both
tables, the so-called natural join.
```{r}
flights2 %>%
left_join(weather)
```

2. A character vector, by = "x". This is like a natural join, but uses
only some of the common variables.

```{r}
flights2 %>%
left_join(planes, by = "tailnum")
```

3. A named character vector: by = c("a" = "b"). This will match
variable a in table x to variable b in table y. The variables from x
will be used in the output.

```{r}
flights2 %>%
left_join(airports, c("dest" = "faa"))

flights2 %>%
left_join(airports, c("origin" = "faa"))
```

10.2.5 Filtering Joins

Filtering joins match observations in the same way as mutating
joins, but affect the observations, not the variables. There are two
types:
• semi_join(x, y) keeps all observations in x that have a match
in y.
• anti_join(x, y) drops all observations in x that have a match
in y.

```{r}
top_dest <- flights %>%
count(dest, sort = TRUE) %>%
head(10)
top_dest

flights %>%
semi_join(top_dest)
```

10.2.6 Join Problems

1. Start by identifying the variables that form the primary key in
each table. You should usually do this based on your understanding
of the data, not empirically by looking for a combination
of variables that give a unique identifier. 

For example, the altitude and longitude uniquely identify each
airport, but they are not good identifiers!

2. Check that none of the variables in the primary key are missing.
If a value is missing then it can’t identify an observation!

3. Check that your foreign keys match primary keys in another
table. The best way to do this is with an anti_join(). It’s common
for keys not to match because of data entry errors. Fixing
these is often a lot of work.
 
If you do have missing keys, you’ll need to be thoughtful about
your use of inner versus outer joins, carefully considering
whether or not you want to drop rows that don’t have a match.

10.2.7 Set Operations

The final type of two-table verb are the set operations. All
these operations work with a complete row, comparing the values of
every variable. These expect the x and y inputs to have the same
variables, and treat the observations like sets:

intersect(x, y)
Return only observations in both x and y.
union(x, y)
Return unique observations in x and y.
setdiff(x, y)
Return observations in x, but not in y.

```{r}
df1 <- tribble(
~x, ~y,
1, 1,
2, 1
)
df2 <- tribble(
~x, ~y,
1, 1,
1, 2
)

intersect(df1, df2)
union(df1, df2)
setdiff(df1, df2)
setdiff(df2, df1)
```
#Factors with forcrats

12.1 Creating Factors

Factor's advantage over character: sorted in an useful way, spot typos
** To create a factor you must start by creating a list of the valid levels:
```{r}
x1 <- c("Dec", "Apr", "Jan", "Mar")
month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
y1 <- factor(x1, levels = month_levels)
y1
sort(y1)
```

Sometimes you’d prefer that the order of the levels match the order of the first appearance in the data. You can do that when creating the factor by setting levels to unique(x), or after the fact, with fct_inorder():

```{r}
f1 <- factor(x1, levels = unique(x1))
f1
f2 <- x1 %>% 
  factor() %>% 
  fct_inorder()
f2
```


When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

